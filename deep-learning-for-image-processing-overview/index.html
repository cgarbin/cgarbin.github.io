<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>An overview of deep learning for image processing - Christian Garbin’s personal blog</title>
<meta name="description" content="Deep learning (large, multi-layered neural networks) have been successfully applied to computer vision tasks. This article reviews its origins, the evolution of network architectures, and recent developments.">


  <meta name="author" content="Christian Garbin">
  
  <meta property="article:author" content="Christian Garbin">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Christian Garbin's personal blog">
<meta property="og:title" content="An overview of deep learning for image processing">
<meta property="og:url" content="https://cgarbin.github.io/deep-learning-for-image-processing-overview/">


  <meta property="og:description" content="Deep learning (large, multi-layered neural networks) have been successfully applied to computer vision tasks. This article reviews its origins, the evolution of network architectures, and recent developments.">







  <meta property="article:published_time" content="2021-04-26T00:00:00-04:00">



  <meta property="article:modified_time" content="2022-02-04T00:00:00-05:00">



  

  


<link rel="canonical" href="https://cgarbin.github.io/deep-learning-for-image-processing-overview/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Christian Garbin",
      "url": "https://cgarbin.github.io/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Christian Garbin's personal blog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Christian Garbin's personal blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/posts/">Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="https://cgarbin.github.io/" itemprop="url">Christian Garbin</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>I am a software engineer at <a href="https://www.mathworks.com/">MathWorks</a> and a Ph.D. candidate at <a href="https://www.fau.edu/">Florida Atlantic University</a>, focusing on machine learning <a href="https://cgarbin.github.io/about/">(more…)</a></p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        
          
        
          
        
          
            <li><a href="https://github.com/fau-masters-collected-works-cgarbin" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
      
      
      
      
    
    
      

<nav class="nav__list">
  <h3 class="nav__title" style="padding-left: 0;"></h3>
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">More...</span>
        

        
        <ul>
          
            <li><a href="/transformers-in-computer-vision"><i class="fas fa-book-open" style="color:blue"></i> Transformers in computer vision</a></li>
          
            <li><a href="/machine-learning-interpretability-feature-attribution"><i class="fas fa-book-open" style="color:blue"></i> Interpretability with feature attribution</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="An overview of deep learning for image processing">
    <meta itemprop="description" content="Deep learning (large, multi-layered neural networks) have been successfully applied to computer vision tasks. This article reviews its origins, the evolution of network architectures, and recent developments.">
    <meta itemprop="datePublished" content="2021-04-26T00:00:00-04:00">
    <meta itemprop="dateModified" content="2022-02-04T00:00:00-05:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="https://cgarbin.github.io/deep-learning-for-image-processing-overview/" class="u-url" itemprop="url">An overview of deep learning for image processing
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#traditional-image-recognition-vs-deep-learning">Traditional image recognition vs. deep learning</a></li><li><a href="#what-deep-learning-networks-learn">What deep learning networks “learn”</a></li><li><a href="#the-evolution-of-deep-learning">The evolution of deep learning</a></li><li><a href="#recent-trends">Recent trends</a></li><li><a href="#keeping-up-with-new-developments">Keeping up with new developments</a></li></ul>

            </nav>
          </aside>
        
        <p>Deep learning revolutionized image processing. It made previous techniques, based on manual feature extraction, obsolete. This article reviews the progress of deep learning, with ever-growing networks and the new developments in the field.</p>

<!--more-->

<p>Deep learning is a sub-area of machine learning, which in turn is a sub-area of artificial intelligence (<a href="https://commons.wikimedia.org/wiki/File:AI-ML-DL.svg">picture source</a>).</p>

<p><img src="/images/2021-02-28/AI-ML-DL.png" alt="Deep learning" /></p>

<p>The best way I found to explain deep learning is in contrast to traditional methods. Yann LeCun, one of the founders of deep learning, gave an <a href="https://www.youtube.com/watch?v=Qk4SqF9FT-M">informative talk</a> on the evolution of learning techniques, starting with the traditional ones and ending with deep learning. He focuses on image recognition in that talk.</p>

<p>It is a worthwhile investment of one hour of our time to listen to someone who was not only present but actively driving the evolution of deep learning. The two pictures immediately below are from his speech.</p>

<h2 id="traditional-image-recognition-vs-deep-learning">Traditional image recognition vs. deep learning</h2>

<p>In traditional image recognition, we use hand-crafted rules to extract features from an image (<a href="https://youtu.be/Qk4SqF9FT-M?t=305">source</a>).</p>

<p><img src="/images/2021-02-28/image-processing-traditional.png" alt="Traditional image processing" /></p>

<p>In contrast, deep learning image recognition is done with trainable, multi-layer neural networks. Instead of hand-crafting the rules, we feed labeled images to the network. The neural network, through the training process, extracts the features needed to identify the images (<a href="https://youtu.be/Qk4SqF9FT-M?t=435">source</a>).</p>

<p><img src="/images/2021-02-28/image-processing-deep-learning.png" alt="Deep learning image processing" /></p>

<p>“Deep” comes from the fact that neural networks (in this application) use several layers. For example, LeNet-5, named after Yann LeCunn (of the presentation above) and shown in the (historic) picture below (<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">source</a>), has seven layers.</p>

<p><img src="/images/2021-02-28/lenet-5.png" alt="Deep learning network example" /></p>

<h2 id="what-deep-learning-networks-learn">What deep learning networks “learn”</h2>

<p>Each layer “learns” (“extracts” is a better technical term) different aspects (“features” in the pictures above) of the images. Lower layers extract basic features (such as edges), and higher layers extract more complex concepts (that frankly, <a href="https://distill.pub/2017/feature-visualization/">we don’t quite know how to explain yet</a>).</p>

<p>The picture below (<a href="https://distill.pub/2017/feature-visualization/">source</a>) shows the features that each layer of a deep learning network extracts. On the left, we have the first layers of the network. They extract basic features, such as edges. As we move to the right, we see the upper layers of the network and the features they extract.</p>

<p><img src="/images/2021-02-28/layer-visualization.png" alt="Visualization of features in layers of a network" /></p>

<p>Unlike traditional image processing, a deep learning network is not manually configured to extract these features. They learn it through the <a href="https://developers.google.com/machine-learning/crash-course/training-neural-networks/video-lecture">training process</a>.</p>

<h2 id="the-evolution-of-deep-learning">The evolution of deep learning</h2>

<p>Deep learning for image processing entered the mainstream in the late 1990s when <a href="https://cs231n.github.io/convolutional-networks/">convolutional neural networks</a> were applied to image processing. After stalling a bit in the early 2000s, deep learning took off in the early 2010s. In a short span of a few years, bigger and bigger network architectures were developed. Over time, what “deep” meant was stretched even further.</p>

<p>The table below shows the evolution of deep learning network architectures.</p>

<table>
  <thead>
    <tr>
      <th>When/What</th>
      <th>Notable features</th>
      <th>Canonical depiction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1990s<br /><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LeNet</a></td>
      <td>Trainable network for image recognition.<br />- Gradient-based learning<br />- Convolutional neural network</td>
      <td><img src="/images/2021-02-28/lenet-5.png" alt="LeNet" /></td>
    </tr>
    <tr>
      <td>2012<br /><a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">AlexNet</a></td>
      <td>One network outperformed, by a large margin, model ensembling (best in class at the time) in <a href="https://www.image-net.org/">ImageNet</a>.<br />- Deep convolutional neural network<br />- Overcame overfitting with data augmentation and dropout</td>
      <td><img src="/images/2021-02-28/alexnet.png" alt="AlexNet" /></td>
    </tr>
    <tr>
      <td>2014<br /><a href="https://arxiv.org/pdf/1409.4842.pdf">Inception</a><br />(GoogLeNet)</td>
      <td>Very deep network (over 20 layers), composed of building blocks, resulting in a “network in a network” (inception).</td>
      <td>Partial depiction<br /><img src="/images/2021-02-28/inception.png" alt="Inception" /></td>
    </tr>
    <tr>
      <td>2014<br /><a href="https://arxiv.org/pdf/1409.1556.pdf">VGGNet</a></td>
      <td>Stacks of small convolution filters (as opposed to one large filter) to reduce the number of parameters in the network.</td>
      <td><img src="/images/2021-02-28/vggnet.png" alt="AlexNet" /></td>
    </tr>
    <tr>
      <td>2015<br /><a href="https://arxiv.org/pdf/1512.03385.pdf">ResNet</a></td>
      <td>Introduced skip connections (residual learning) to train very deep networks (152 layers). At the same time, the network is compact (few parameters for its size).</td>
      <td>Partial depiction<br /><img src="/images/2021-02-28/resnet.png" alt="Inception" /></td>
    </tr>
  </tbody>
</table>

<p>Network architectures continue to evolve today. So many architectures have been put into practice that we now need a <a href="https://arxiv.org/abs/1901.06032">taxonomy to categorize them</a>.</p>

<p><img src="/images/2021-02-28/taxonomy.png" alt="CNN taxonomy" /></p>

<h2 id="recent-trends">Recent trends</h2>

<ul>
  <li><em>Efficiently scaling CNNs</em>: There are different ways to scale CNN-based networks. The <a href="https://arxiv.org/abs/1905.11946">EfficientNet</a> family of networks shows that we don’t always need large CNN networks to get good results.</li>
  <li><em>Back to basics</em>: The <a href="https://arxiv.org/abs/2105.01601">MLP-Mixer</a> network does away with CNN layers altogether. It uses only simpler multi-layer perceptron (MLP) layers, resulting in networks with faster throughput, predicting more images per second than other network architectures.</li>
  <li><em>Transformers</em>: Transformer-based networks, after their success with natural language processing (NLP), <a href="/transformers-in-computer-vision/">are being applied to image processing</a>.</li>
  <li><em>Learning concepts</em>: by training with images and their textual descriptions (multimodal learning), OpenAI created <a href="https://openai.com/blog/clip/">CLIP</a>, a network that seems to have learned the concepts of images. Traditional image classification relied on extracting features from the images. They work well on images with the same characteristics but fail when they are different. For example, they identify the picture of a banana but not the sketch of a banana. On the other hand, CLIP seems to have learned the concept of the images. It identifies pictures and sketches of bananas (see the illustration in the <a href="https://openai.com/blog/clip/">article</a>)</li>
</ul>

<h2 id="keeping-up-with-new-developments">Keeping up with new developments</h2>

<p><a href="https://paperswithcode.com/">Papers with Code</a> maintains a <a href="https://paperswithcode.com/sota/image-classification-on-imagenet">leaderboard of the state of the art</a>, including links to the papers that describe the network used to achieve each result.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/computer-vision" class="page__taxonomy-item p-category" rel="tag">computer-vision</a><span class="sep">, </span>
    
      <a href="/tags/deep-learning" class="page__taxonomy-item p-category" rel="tag">deep-learning</a><span class="sep">, </span>
    
      <a href="/tags/machine-learning" class="page__taxonomy-item p-category" rel="tag">machine-learning</a>
    
    </span>
  </p>




        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-02-04">February 4, 2022</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=An+overview+of+deep+learning+for+image+processing%20https%3A%2F%2Fcgarbin.github.io%2Fdeep-learning-for-image-processing-overview%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fcgarbin.github.io%2Fdeep-learning-for-image-processing-overview%2F&title=An overview of deep learning for image processing" class="btn  btn--reddit" title="Share on Reddit"><i class="fab fa-fw fa-reddit" aria-hidden="true"></i><span> Reddit</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fcgarbin.github.io%2Fdeep-learning-for-image-processing-overview%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/shap-experiments-image-classification/" class="pagination--pager" title="Exploring SHAP explanations for image classification
">Previous</a>
    
    
      <a href="/machine-learning-interpretability-feature-attribution/" class="pagination--pager" title="Machine learning interpretability with feature attribution
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/how-to-read-and-write-a-paper/" rel="permalink">Improve writing by learning how to read
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Turn the advice in “How to Read a Paper” around to write a good paper.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/using-llms-for-summarization/" rel="permalink">Using LLMs to summarize GitHub issues
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          16 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A learning exercise on using large language models (LLMs) for summarization. It uses GitHub issues as a practical use case that we can relate to.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/writing-good-jupyter-notebooks/" rel="permalink">Writing good Jupyter notebooks
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">How to write well-structured, understandable, flexible, and resilient Jupyter notebooks.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/vision-transformers-properties/" rel="permalink">Vision transformer properties
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Vision transformers are not just a replacement for CNNs and RNNs. They have some interesting properties.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://github.com/fau-masters-collected-works-cgarbin" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Christian Garbin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>

var store = [{
        "title": "Artificial intelligence and jobs",
        "excerpt":"One of my favorites sources to keep track of current affairs, The Economist, published in January of 2021 a column on the effect of automation on jobs, “New research shows the robots are coming for jobs—but stealthily” (need a subscription to read in full). Among the reasons I like The...","categories": [],
        "tags": ["artificial-intelligence","machine-learning","social-impact"],
        "url": "/ai-and-jobs/",
        "teaser": null
      },{
        "title": "Bias in data science and machine learning",
        "excerpt":"Of all the problems that may crop up in the machine learning lifecycle (acquire data, train a model, test the model, deploy, and monitor), biased data is the one that worries me the most because it starts in the very first step, when we acquire data for the model. All...","categories": [],
        "tags": ["data-science","machine-learning","bias","social-impact"],
        "url": "/bias-data-science-machine-learning/",
        "teaser": null
      },{
        "title": "Would you trust AI to do [X]?",
        "excerpt":"Taking a narrow definition of the question, where [X] is a reasonable application of AI for the current state of the technologies involved, “trust” can be formulated as “it is safe to assume that an AI product can do [X] consistently and that it also detects when it is working...","categories": [],
        "tags": ["machine-learning","failure"],
        "url": "/would-you-trust-ai-to-do-x/",
        "teaser": null
      },{
        "title": "Explainability: end-users considerations",
        "excerpt":"If we assume that explaining to the end-users how a machine learning (ML) model makes its predictions increases their trust on that model (side note: it can be debated if explaining a prediction is sufficient to establish trust, but in general we can assume that explaining contributes to increasing trust),...","categories": [],
        "tags": ["machine-learning","explainability","interpretability"],
        "url": "/explainability-user-considerations/",
        "teaser": null
      },{
        "title": "Fairness in machine learning: a reading list",
        "excerpt":"This article lists resources to understand concepts and applications of fairness in machine learning (ML). Sources for people in a hurry “I can dedicate at most one hour of my life to fairness in ML” In that case, watch the video 21 fairness definitions and their politics. Narayanan is an...","categories": [],
        "tags": ["machine-learning","bias","fairness","social-impact"],
        "url": "/fairness-a-reading-list/",
        "teaser": null
      },{
        "title": "What is \"model accuracy\", really?",
        "excerpt":"In the book Responsible Machine Learning, when discussing trust and risk, the authors recommend a list of questions to ask to understand the risk of a machine learning (ML) deployment. One of the questions is “What is the quality of the model? (Accuracy, AUC/ROC, F1)”. These metrics compare correct and...","categories": [],
        "tags": ["machine-learning","accuracy","roc"],
        "url": "/decision-threshold-effect-on-accuracy/",
        "teaser": null
      },{
        "title": "Machine learning, but not understanding",
        "excerpt":"In the expression machine learning, are the machines actually learning anything? In the book “Artificial Intelligence, a guide for thinking humans” Melanie Mitchell explains that “Learning in neural networks simply consists in gradually modifying the weights on connections so that each output’s error gets as close to 0 as possible...","categories": [],
        "tags": ["machine-learning","failure"],
        "url": "/machine-learning-but-not-understanding/",
        "teaser": null
      },{
        "title": "Exploring SHAP explanations for image classification",
        "excerpt":"This article explores how to interpret predictions of an image classification neural network using SHAP (SHapley Additive exPlanations). The goals of the experiments are to: Explore how SHAP explains the predictions. This experiment uses a (fairly) accurate network to understand how SHAP attributes the predictions. Explore how SHAP behaves with...","categories": [],
        "tags": ["machine-learning","computer-vision","image-classification","explainability","interpretability","shap"],
        "url": "/shap-experiments-image-classification/",
        "teaser": null
      },{
        "title": "An overview of deep learning for image processing",
        "excerpt":"Deep learning revolutionized image processing. It made previous techniques, based on manual feature extraction, obsolete. This article reviews the progress of deep learning, with ever-growing networks and the new developments in the field. Deep learning is a sub-area of machine learning, which in turn is a sub-area of artificial intelligence...","categories": [],
        "tags": ["machine-learning","deep-learning","computer-vision"],
        "url": "/deep-learning-for-image-processing-overview/",
        "teaser": null
      },{
        "title": "Machine learning interpretability with feature attribution",
        "excerpt":"There are many discussions in the machine learning (ML) community about model interpretability and explainability. The discussions take place in several contexts, ranging from using interpretability and explainability techniques to increase the robustness of a model, all the way to increasing end-user trust in a model. This article reviews feature...","categories": [],
        "tags": ["machine-learning","explainability","interpretability","shap"],
        "url": "/machine-learning-interpretability-feature-attribution/",
        "teaser": null
      },{
        "title": "Applications of transformers in computer vision",
        "excerpt":"This article describes the evolution of transformers, their application in natural language processing (NLP), their surprising effectiveness in computer vision, ending with applications in healthcare. It starts with the motivation and origins of transformers, from the initial attempts to apply a specialized neural network architecture (recurrent neural network – RNN)...","categories": [],
        "tags": ["machine-learning","computer-vision","transformers"],
        "url": "/transformers-in-computer-vision/",
        "teaser": null
      },{
        "title": "Understanding transformers in one morning",
        "excerpt":"Transformers are (deservedly so) a hot topic in machine learning. If you are new to transformers, the resources in this article will help you understand their fundamentals and applications. It will take about one morning (four hours, give or take) to go through all items. I created the list after...","categories": [],
        "tags": ["machine-learning","natural-language-processing","nlp","transformers"],
        "url": "/understanding-transformers-in-one-morning/",
        "teaser": null
      },{
        "title": "Vision transformer properties",
        "excerpt":"Transformers crossed over from natural language into computer vision in a few low-key steps until the An Image is Worth 16x16 Words paper exploded into the machine learning scene late in 2020. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) were the dominant architectures in computer vision tasks until...","categories": [],
        "tags": ["machine-learning","computer-vision","transformers"],
        "url": "/vision-transformers-properties/",
        "teaser": null
      },{
        "title": "Writing good Jupyter notebooks",
        "excerpt":"Jupyter notebooks are an excellent tool for data scientists and machine learning practitioners. However, if not approached with a few techniques, they can turn into a pile of unintelligible, unmaintainable code. This post will discuss some techniques I use to write good Jupyter notebooks. We will start with a notebook...","categories": [],
        "tags": ["jupyter-notebooks","python","data-science"],
        "url": "/writing-good-jupyter-notebooks/",
        "teaser": null
      },{
        "title": "Using LLMs to summarize GitHub issues",
        "excerpt":"This project is a learning exercise on using large language models (LLMs) for summarization. It uses GitHub issues as a practical use case that we can relate to. The goal is to allow developers to understand what is being reported and discussed in the issues without having to read each...","categories": [],
        "tags": ["generative-ai","llm","summarization","prompt-engineering"],
        "url": "/using-llms-for-summarization/",
        "teaser": null
      },{
        "title": "Improve writing by learning how to read",
        "excerpt":"The advice in How to Read a Paper changed how I read scientific papers. I used to read them linearly, struggling through each section in order. The three-pass approach was liberating. It freed my mind from having to understand everything the first time. Eventually, I realized I could turn the...","categories": [],
        "tags": ["writing","reading","papers"],
        "url": "/how-to-read-and-write-a-paper/",
        "teaser": null
      }]

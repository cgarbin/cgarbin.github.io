<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Fairness in machine learning: a reading list - Christian Garbin’s personal blog</title>
<meta name="description" content="A list of resources to understand concepts and applications of fairness in machine learning (ML).">


  <meta name="author" content="Christian Garbin">
  
  <meta property="article:author" content="Christian Garbin">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Christian Garbin's personal blog">
<meta property="og:title" content="Fairness in machine learning: a reading list">
<meta property="og:url" content="https://cgarbin.github.io/fairness-a-reading-list/">


  <meta property="og:description" content="A list of resources to understand concepts and applications of fairness in machine learning (ML).">



  <meta property="og:image" content="https://cgarbin.github.io/images/2021-03-18/justice.jpg">





  <meta property="article:published_time" content="2021-03-18T00:00:00-04:00">





  

  


<link rel="canonical" href="https://cgarbin.github.io/fairness-a-reading-list/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Christian Garbin",
      "url": "https://cgarbin.github.io/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Christian Garbin's personal blog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Christian Garbin's personal blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/posts/">Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: url('/images/2021-03-18/justice.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Fairness in machine learning: a reading list

        
      </h1>
      
        <p class="page__lead">A list of resources to understand concepts and applications of fairness in machine learning (ML).
</p>
      
      

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


      
      
    </div>
  
  
    <span class="page__hero-caption">Photo credit: <a href="https://commons.wikimedia.org/wiki/File:Justice.tif">Ludmila Kvapilova, CC BY-SA 4.0, via Wikimedia Commons</a>
</span>
  
</div>







<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="https://cgarbin.github.io/" itemprop="url">Christian Garbin</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>I am a software engineer at <a href="https://www.mathworks.com/">MathWorks</a> and a Ph.D. candidate at <a href="https://www.fau.edu/">Florida Atlantic University</a>, focusing on machine learning <a href="https://cgarbin.github.io/about/">(more…)</a></p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        
          
        
          
        
          
            <li><a href="https://github.com/fau-masters-collected-works-cgarbin" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
      
      
      
      
    
    
      

<nav class="nav__list">
  <h3 class="nav__title" style="padding-left: 0;"></h3>
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">More...</span>
        

        
        <ul>
          
            <li><a href="/bias-data-science-machine-learning"><i class="fas fa-book-open" style="color:blue"></i> Bias in data science and machine learning</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Fairness in machine learning: a reading list">
    <meta itemprop="description" content="A list of resources to understand concepts and applications of fairness in machine learning (ML).">
    <meta itemprop="datePublished" content="2021-03-18T00:00:00-04:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#sources-for-people-in-a-hurry">Sources for people in a hurry</a><ul><li><a href="#i-can-dedicate-at-most-one-hour-of-my-life-to-fairness-in-ml">“I can dedicate at most one hour of my life to fairness in ML”</a></li><li><a href="#if-i-could-recommend-only-one-source">“If I could recommend only one source…”</a></li></ul></li><li><a href="#other-sources">Other sources</a><ul><li><a href="#conceptual">Conceptual</a></li><li><a href="#keeping-up-with-the-latest-research">Keeping up with the latest research</a></li><li><a href="#recent-survey-papers">Recent survey papers</a></li><li><a href="#social-and-legal-implications">Social and legal implications</a></li><li><a href="#healthcare-specific">Healthcare specific</a></li></ul></li><li><a href="#bias-and-fairness">Bias and fairness</a></li></ul>

            </nav>
          </aside>
        
        <p>This article lists resources to understand concepts and applications of fairness in machine learning (ML).</p>

<!--more-->

<h2 id="sources-for-people-in-a-hurry">Sources for people in a hurry</h2>

<h3 id="i-can-dedicate-at-most-one-hour-of-my-life-to-fairness-in-ml">“I can dedicate at most one hour of my life to fairness in ML”</h3>

<p>In that case, watch the video <a href="https://fairmlbook.org/tutorial2.html">21 fairness definitions and their politics</a>.</p>

<p>Narayanan is an enganging speaker. He is also well-grounded in the subject, as one of the authors of the <a href="https://fairmlbook.org/">fairmlbook.org book (Fairness and Machine Learning: Limitations and Opportunities)</a>. In one hour he covers the complexity of the topic and the state of the research on it (as of 2018, but the fundamentals of the problem are still the same). This is a good source to understand the complexity of the problem and why solutions are not easy (and sometimes contradictory).</p>

<!--more-->

<h3 id="if-i-could-recommend-only-one-source">“If I could recommend only one source…”</h3>

<p>Of all the sources below, if I could recommend only one (well, one for concepts, one for visualization, and one for a programming project):</p>

<ul>
  <li>Concepts: <a href="https://fairmlbook.org/">Fairness and Machine Learning: Limitations and Opportunities</a></li>
  <li>Visualization: <a href="https://pair.withgoogle.com/explorables/measuring-fairness/">Measuring Fairness explorable</a></li>
  <li>In practice (programming): <a href="https://developers.google.com/machine-learning/crash-course/fairness/video-lecture">Fairness | Machine Learning Crash Course</a></li>
</ul>

<h2 id="other-sources">Other sources</h2>

<h3 id="conceptual">Conceptual</h3>

<p>This section lists sources to understand the concepts of fairness and their implications for society, in no particular order.</p>

<p><a href="https://arxiv.org/abs/1901.10002">A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle</a></p>

<p>Bias is closely related to fairness. This paper describes a framework to understand sources of bias in machine learning. Once we understand where bias comes from, we are better positioned to eliminate or at least mitigate it. The picture below summarizes the framework, illustrating the sources of bias in machine learning.</p>

<p><img src="/images/2021-03-18/sources-of-bias.png" alt="A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle" /></p>

<p><a href="https://fairmlbook.org/">Fairness and Machine Learning: Limitations and Opportunities</a></p>

<p>Also known as the “fair ML book”, from the site URL, <a href="https://fairmlbook.org/">fairmlbook.org</a>. A free online book from luminaries of the field. It’s updated frequently. If we could have only one reference for concepts, this would be it.</p>

<p><a href="https://fairmlclass.github.io/">CS 294: Fairness in Machine Learning</a></p>

<p>From the authors of <a href="https://fairmlbook.org/">fairmlbook.org</a> (previous item). A note at the top says “For an updated resource, please see fairmlbook.org.” However, it is still a good source because the sequence of lectures is a structured way to understand/explore fairness and has many pointers to other references.</p>

<p><a href="https://fairmlbook.org/tutorial2.html">21 fairness definitions and their politics</a></p>

<p>Continuing the <a href="https://fairmlbook.org/">fairmlbook.org</a> theme, this is a one-hour presentation by one of the authors. It is a good source to learn in a short time the complexities of the field (and thus, the complexity of the solutions).</p>

<h3 id="keeping-up-with-the-latest-research">Keeping up with the latest research</h3>

<p>Visit the <a href="https://paperswithcode.com/task/fairness">Papers With Code fairness section</a> frequently for the latest papers, libraries, and datasets on the topic.</p>

<h3 id="recent-survey-papers">Recent survey papers</h3>

<p>These are some recent survey papers on fairness as of early 2021. Each has a brief extract to help explain why it is relevant and what aspects it covers.</p>

<p><a href="https://arxiv.org/abs/1908.09635">A Survey on Bias and Fairness in Machine Learning</a></p>

<blockquote>
  <p>In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them.</p>
</blockquote>

<p><a href="https://arxiv.org/abs/1903.03425">The Ethics of AI Ethics – An Evaluation of Guidelines</a></p>

<blockquote>
  <p>Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. […] Designed as a comprehensive evaluation, this paper analyzes and compares these guidelines highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems – and how the effectiveness in the demands of AI ethics can be improved.</p>
</blockquote>

<p><a href="https://arxiv.org/abs/1905.06876">From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices</a></p>

<blockquote>
  <p>[O]ur intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the pipeline, and to signal to researchers where further work is needed. The focus is exclusively on Machine Learning, but it is hoped that the results of this research may be easily applicable to other branches of AI. The article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs.</p>
</blockquote>

<p><a href="https://dl.acm.org/doi/10.1145/3287560.3287600">50 Years of Test (Un)fairness: Lessons for Machine Learning</a></p>

<blockquote>
  <p>We compare past and current notions of fairness along several dimensions, including the fairness criteria, the focus of the criteria (e.g., a test, a model, or its use), the relationship of fairness to individuals, groups, and subgroups, and the mathematical method for measuring fairness (e.g., classification, regression). This work points the way towards future research and measurement of (un)fairness that builds from our modern understanding of fairness while incorporating insights from the past.</p>
</blockquote>

<p><a href="https://arxiv.org/abs/2112.05700">A Framework for Fairness: A Systematic Review of Existing Fair AI Solutions</a></p>

<blockquote>
  <p>A large portion of fairness research has gone to producing tools that machine learning practitioners can use to audit for bias while designing their algorithms. Nonetheless, there is a lack of application of these fairness solutions in practice. This systematic review provides an in-depth summary of the algorithmic bias issues that have been defined and the fairness solution space that has been proposed. Moreover, this review provides an in-depth breakdown of the caveats to the solution space that have arisen since their release and a taxonomy of needs that have been proposed by machine learning practitioners, fairness researchers, and institutional stakeholders</p>
</blockquote>

<h3 id="social-and-legal-implications">Social and legal implications</h3>

<p>Not all aspects of machine learning fairness are technical. We care about fairness because it affects humans at the individual and societal levels. These are some papers that look at the social and legal implications of fairness in machine learning.</p>

<p><a href="https://arxiv.org/abs/1909.11869">This Thing Called Fairness: Disciplinary Confusion Realizing a Value in Technology</a></p>

<blockquote>
  <p>[T]his paper examines the value of shared vocabularies, analytics, and other tools that facilitate conversations about values in light of these disciplinary specific conceptualizations, the role such tools play in furthering research and practice, outlines different conceptions of “fairness” deployed in discussions about computer systems, and provides an analytic tool for interdisciplinary discussions and collaborations around the concept of fairness. We use a case study of risk assessments in criminal justice applications to both motivate our effort–describing how conflation of different concepts under the banner of “fairness” led to unproductive confusion–and illustrate the value of the fairness analytic by demonstrating how the rigorous analysis it enables can assist in identifying key areas of theoretical, political, and practical misunderstanding or disagreement, and where desired support alignment or collaboration in the absence of consensus.</p>
</blockquote>

<p>My (Christian’s) commentary: highly analytical, with strong definitions of fairness from different points of view (section 5). Then it tackles the controversial COMPAS (Section 7) system and argues, among other points, that analyzing only the algorithm and not the entire system is shortsighted. Appendix A, “An Analytic for applying contested conceptions of fairness in computer systems,” is worth the paper alone.</p>

<p><a href="https://arxiv.org/abs/1912.00761">On the Legal Compatibility of Fairness Definitions</a></p>

<blockquote>
  <p>Past literature has been effective in demonstrating ideological gaps in machine learning (ML) fairness definitions when considering their use in complex sociotechnical systems. However, we go further to demonstrate that these definitions often misunderstand the legal concepts from which they purport to be inspired, and consequently inappropriately co-opt legal language. In this paper, we demonstrate examples of this misalignment and discuss the differences in ML terminology and their legal counterparts […].</p>
</blockquote>

<h3 id="healthcare-specific">Healthcare specific</h3>

<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347576/">Potential Biases in Machine Learning Algorithms Using Electronic Health Record Data</a></p>

<blockquote>
  <p>This Special Communication outlines the potential biases that may be introduced into machine learning–based clinical decision support tools that use electronic health record data and proposes potential solutions to the problems of overreliance on automation, algorithms based on biased data, and algorithms that do not provide information that is clinically meaningful.</p>
</blockquote>

<h2 id="bias-and-fairness">Bias and fairness</h2>

<p>Bias is a close cousin to fairness. Read more about bias in <a href="/bias-data-science-machine-learning/">this post</a>.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/bias" class="page__taxonomy-item p-category" rel="tag">bias</a><span class="sep">, </span>
    
      <a href="/tags/fairness" class="page__taxonomy-item p-category" rel="tag">fairness</a><span class="sep">, </span>
    
      <a href="/tags/machine-learning" class="page__taxonomy-item p-category" rel="tag">machine-learning</a><span class="sep">, </span>
    
      <a href="/tags/social-impact" class="page__taxonomy-item p-category" rel="tag">social-impact</a>
    
    </span>
  </p>




        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2021-03-18T00:00:00-04:00">March 18, 2021</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Fairness+in+machine+learning%3A+a+reading+list%20https%3A%2F%2Fcgarbin.github.io%2Ffairness-a-reading-list%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fcgarbin.github.io%2Ffairness-a-reading-list%2F&title=Fairness in machine learning: a reading list" class="btn  btn--reddit" title="Share on Reddit"><i class="fab fa-fw fa-reddit" aria-hidden="true"></i><span> Reddit</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fcgarbin.github.io%2Ffairness-a-reading-list%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/explainability-user-considerations/" class="pagination--pager" title="Explainability: end-users considerations
">Previous</a>
    
    
      <a href="/decision-threshold-effect-on-accuracy/" class="pagination--pager" title="What is “model accuracy”, really?
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/how-to-read-and-write-a-paper/" rel="permalink">Improve writing by learning how to read
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Turn the advice in “How to Read a Paper” around to write a good paper.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/using-llms-for-summarization/" rel="permalink">Using LLMs to summarize GitHub issues
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          16 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A learning exercise on using large language models (LLMs) for summarization. It uses GitHub issues as a practical use case that we can relate to.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/writing-good-jupyter-notebooks/" rel="permalink">Writing good Jupyter notebooks
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">How to write well-structured, understandable, flexible, and resilient Jupyter notebooks.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/vision-transformers-properties/" rel="permalink">Vision transformer properties
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Vision transformers are not just a replacement for CNNs and RNNs. They have some interesting properties.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://github.com/fau-masters-collected-works-cgarbin" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Christian Garbin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
